
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://antoniocampos13.github.io/theme/stylesheet/style.min.css">


    <link id="pygments-light-theme" rel="stylesheet" type="text/css"
          href="https://antoniocampos13.github.io/theme/pygments/vs.min.css">


  <link rel="stylesheet" type="text/css" href="https://antoniocampos13.github.io/theme/font-awesome/css/fontawesome.css">
  <link rel="stylesheet" type="text/css" href="https://antoniocampos13.github.io/theme/font-awesome/css/brands.css">
  <link rel="stylesheet" type="text/css" href="https://antoniocampos13.github.io/theme/font-awesome/css/solid.css">


    <link href="https://antoniocampos13.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Antonio's Portfolio Atom">

    <link href="https://antoniocampos13.github.io/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Antonio's Portfolio RSS">


  

    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#333333">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#333333">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Microsoft EDGE -->
    <meta name="msapplication-TileColor" content="#333333">

 

<meta name="author" content="Antonio Victor Campos Coelho" />
<meta name="description" content="Introduction Hello, long time no see! Since I lasted posted, many things happened. Since March I have been working as Post-Doc Researcher, hired by the Hospital Israelita Albert Einstein (HIAE, São Paulo, Brazil) to work for the Projeto Genomas Raros (“Rare Genomes Project”, GRAR from here on), a public-private partnership …" />
<meta name="keywords" content="Bioinformatics, Genomics, Hail">


  <meta property="og:site_name" content="Antonio's Portfolio"/>
  <meta property="og:title" content="Genomic Analysis With Hail"/>
  <meta property="og:description" content="Introduction Hello, long time no see! Since I lasted posted, many things happened. Since March I have been working as Post-Doc Researcher, hired by the Hospital Israelita Albert Einstein (HIAE, São Paulo, Brazil) to work for the Projeto Genomas Raros (“Rare Genomes Project”, GRAR from here on), a public-private partnership …"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="https://antoniocampos13.github.io/genomic-analysis-with-hail.html"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2021-07-09 16:45:00-03:00"/>
  <meta property="article:modified_time" content=""/>
  <meta property="article:author" content="https://antoniocampos13.github.io/author/antonio-victor-campos-coelho.html">
  <meta property="article:section" content="Python"/>
  <meta property="article:tag" content="Bioinformatics"/>
  <meta property="article:tag" content="Genomics"/>
  <meta property="article:tag" content="Hail"/>
  <meta property="og:image" content="https://avatars.githubusercontent.com/antoniocampos13">

  <title>Antonio's Portfolio &ndash; Genomic Analysis With Hail</title>

</head>
<body class="light-theme">
  <aside>
    <div>
      <a href="https://antoniocampos13.github.io/">
        <img src="https://avatars.githubusercontent.com/antoniocampos13" alt="Antonio's Portfolio" title="Antonio's Portfolio">
      </a>

      <h1>
        <a href="https://antoniocampos13.github.io/">Antonio's Portfolio</a>
      </h1>

<p>PhD in Genetics</p>

      <nav>
        <ul class="list">


              <li>
                <a target="_self"
                   href="https://antoniocampos13.github.io/pages/about.html#about">
                  About
                </a>
              </li>
              <li>
                <a target="_self"
                   href="https://antoniocampos13.github.io/pages/contact.html#contact">
                  Contact
                </a>
              </li>

            <li>
              <a target="_self" href="http://lattes.cnpq.br/2986394950644755" >Brazilian Lattes CV</a>
            </li>
            <li>
              <a target="_self" href="https://scholar.google.com.br/citations?user=d2ij4wUAAAAJ&hl" >Google Scholar</a>
            </li>
            <li>
              <a target="_self" href="https://orcid.org/0000-0003-2143-9701" >ORCID</a>
            </li>
            <li>
              <a target="_self" href="http://www.webofscience.com/wos/author/record/E-6795-2015" >ResearcherID Profile</a>
            </li>
        </ul>
      </nav>

      <ul class="social">
          <li>
            <a  class="sc-github" href="https://github.com/antoniocampos13/portfolio" target="_blank">
              <i class="fab fa-github"></i>
            </a>
          </li>
          <li>
            <a  class="sc-linkedin" href="https://www.linkedin.com/in/antonio-coelho-9aa338164" target="_blank">
              <i class="fab fa-linkedin"></i>
            </a>
          </li>
      </ul>
    </div>

  </aside>
  <main>

    <nav>
      <a href="https://antoniocampos13.github.io/">Home</a>

      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>

      <a href="https://antoniocampos13.github.io/feeds/all.atom.xml">Atom</a>

      <a href="https://antoniocampos13.github.io/feeds/all.rss.xml">RSS</a>
    </nav>

<article class="single">
  <header>
      
    <h1 id="genomic-analysis-with-hail">Genomic Analysis With&nbsp;Hail</h1>
    <p>
      Posted on Fri 09 July 2021 in <a href="https://antoniocampos13.github.io/category/python.html">Python</a>

    </p>
  </header>


  <div>
    <h2>Introduction</h2>
<p>Hello, long time no see! Since I lasted posted, many things happened. Since March I have been working as Post-Doc Researcher, hired by the <a href="https://www.einstein.br/Pages/Home.aspx">Hospital Israelita Albert Einstein (<span class="caps">HIAE</span>, São Paulo, Brazil)</a> to work for the Projeto Genomas Raros (&#8220;Rare Genomes Project&#8221;, <span class="caps">GRAR</span> from here on), a public-private partnership between <span class="caps">HIAE</span> and the Brazilian Health Ministry to further the implementation of genomic analysis into the Brazilian public healthcare system (<span class="caps">SUS</span>), with the intention of improve diagnostic rates of rare diseases in Brazil. Since 2020, thousands of genomes of Brazilian patients with suspected rare diseases have been sequenced, and many more will come in the next two&nbsp;years.</p>
<p>Thus, I have been tasked to develop/adapt analysis pipelines to handle whole-genome data at large scales compatible with the scope of <span class="caps">GRAR</span>. My team asked me to explore <a href="https://hail.is/">Hail, a Python/Spark framework for scalable genomic analysis</a>. It has been developed at <a href="https://www.broadinstitute.org/">Broad Institute</a> and was used to generate the <a href="https://gnomAD.broadinstitute.org/">Genome Aggregation Database (gnomAD)</a>.</p>
<p>In this post I will share some use cases of this tool full of potential. Please notice that it is not intended to substitute the official documentation of Hail, <span class="caps">GATK</span> and other software used here. Just consider it as a demonstration of Hail use cases with commentaries. Also, notice two important things: first, Hail implements &#8220;lazy evaluation&#8221;; new users may think a specific command run blazingly fast, but in reality, Hail just mapped the execution order of functions needed and only will compute anything when necessary, such as saving results to disk and printing the first few rows of a dataset to Python&#8217;s standard output stream. Second, Hail need a lot of <span class="caps">RAM</span> and <span class="caps">CPU</span> to work properly with big datasets. Hail is intended to be used in cloud/cluster computing environments, but a computer with relatively good hardware configuration can run small&nbsp;datasets.</p>
<h2>Installing&nbsp;software</h2>
<p>Prepare your Unix computing environment by installing <a href="https://hail.is/#install">Hail</a>, <a href="https://pypi.org/project/gnomAD/">gnomAD utilities for Hail</a> and <a href="https://gatk.broadinstitute.org/hc/en-us">Genome Analysis Toolkit version 4 (<span class="caps">GATK4</span>)</a>. Tools for manipulating <span class="caps">VCF</span> files are essential too, such as <a href="http://samtools.github.io/bcftools/bcftools.html">bcftools</a>. I advise installing the tools into a virtual environment for convenience (see <a href="https://antoniocampos13.github.io/setting-up-your-unix-computer-for-bioinformatics-analysis.html">my previous post</a> for some pointers on how to use conda&nbsp;environments).</p>
<h2>Preparing the multi-sample <span class="caps">VCF</span>&nbsp;input</h2>
<p>Since the <span class="caps">GRAR</span> data is coming from whole-genome sequencing (<span class="caps">WGS</span>), we have been generating one <a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035531812-GVCF-Genomic-Variant-Call-Format">genomic variant call format (gVCF) file</a> per participant through <a href="https://www.illumina.com/products/by-type/informatics-products/dragen-bio-it-platform.html">Illumina&#8217;s <span class="caps">DRAGEN</span> sequencing read analysis platform</a>. A gVCF file has all the characteristics of a <a href="https://samtools.github.io/hts-specs/VCFv4.2.pdf"><span class="caps">VCF</span> file</a>, the difference being that the gVCF files have information for all sites in the genome, which give more precision during the integration of variant calls coming from several&nbsp;samples.</p>
<p>By integration I mean <strong>combining</strong> several gVCF files into a single multi-sample <span class="caps">VCF</span> file so we can perform analysis (calculate allelic frequencies, assess genotyping quality, and so on) with the <strong>whole cohort</strong>. We are currently using <span class="caps">GATK</span>&#8217;s GenomicsDBImport tool. See <a href="https://gatk.broadinstitute.org/hc/en-us/articles/360036883491-GenomicsDBImport">here</a> for a tutorial of how to use it. Briefly, we intend to create a GenomicsDB object and we will update it regularly by appending new gVCFs as they become available, until the last participant is recruited and we have their genome sequenced. When this moment comes, we will extract a multi-sample <span class="caps">VCF</span> with <span class="caps">GATK</span>&#8217;s <code>GenotypeGVCFs</code> tool:</p>
<div class="highlight"><pre><span></span><code>gatk GenotypeGVCFs -R <span class="nv">$REF</span> -V <span class="nv">$DBPATH</span> -G StandardAnnotation -O cohort.vcf
</code></pre></div>

<p>Where <code>$REF</code> and <code>$DBPATH</code> are the paths of the genome reference (the same used during the variant call process) and the GenomicsDB, respectively (which should have a <code>gendb://</code> prefix as noted in the GenomicsDBImport tutorial, something like <code>gendb://my_database</code>). The <code>-O</code> flag indicates the output name. If you wish to compress the <span class="caps">VCF</span> file, you may use <code>bcftools</code> or <code>bgzip</code>. Remember to index the compressed&nbsp;file:</p>
<div class="highlight"><pre><span></span><code>bcftools view cohort.vcf -Oz -o cohort.vcf.gz
bcftools index cohort.vcf.gz

<span class="c1"># or</span>
bgzip -@ <span class="m">4</span> cohort.vcf
tabix cohort.vcf.gz
</code></pre></div>

<p>The next step is to perform <span class="caps">GATK</span>&#8217;s Variant Quality Score Recalibration (<span class="caps">VQSR</span>) in the output <span class="caps">VCF</span> with <span class="caps">GATK</span>&#8217;s <code>VariantRecalibrator</code>.  See their original tutorial <a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035531112--How-to-Filter-variants-either-with-VQSR-or-by-hard-filtering">here</a>. To put it simply, <span class="caps">VQSR</span> works by comparing the detected variants with high-confidence variant sites observed by several consortia (HapMap, 1000 Genomes etc.) and applies a filter deeming the variant a true positive (i.e. the observed variation is a true biological event) or a false positive (i.e. the observed variation is not real, it is in a fact sequencing artifact). To this end, I downloaded high-confidence datasets to perform the <span class="caps">VQSR</span>. The datasets can be found at the <a href="https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=&amp;forceOnObjectsSortingFiltering=false"><span class="caps">GATK</span> Google Cloud Storage (Resource Bundle)</a> and can be downloaded with <a href="https://cloud.google.com/storage/docs/gsutil"><code>gsutil</code> application</a>.</p>
<p>I will post a script with slight modification in the steps of the <span class="caps">VQSR</span> tutorial in my <a href="https://github.com/antoniocampos13/portfolio/tree/master/Python/2021_07_07_Genomic_Analysis_With_Hail">portfolio</a> (I was having errors so I noticed that I had to put spaces after the <code>-resource</code> flags of the <code>VariantRecalibrator</code> command). Briefly, the steps&nbsp;are:</p>
<ol>
<li>Filtering samples with excess of heterozygotes (recommended when working with thousands of&nbsp;samples);</li>
<li>Make a sites-only <span class="caps">VCF</span>;</li>
<li>Recalibration step (separately by indels/mixed and <span class="caps">SNP</span>&nbsp;loci);</li>
<li>Apply the recalibration&nbsp;filters.</li>
</ol>
<p>The output of the <span class="caps">VQSR</span> is the <code>snp.recalibrated.vcf.gz</code> file (despite the name, the indels/mixed variants in the file have been recalibrated as well). We can now import the dataset into&nbsp;Hail.</p>
<h2>Initiating&nbsp;Hail</h2>
<p>Hail&#8217;s frontend is written in Python. Simply importing the Hail module is not sufficient. We must initiate it so it can communicate with Spark. I created the <code>hail_demo_init.py</code> file as an &#8220;init template&#8221; that can be reused between Hail&nbsp;scripts/sessions:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># hail_demo_init.py</span>
<span class="kn">import</span> <span class="nn">hail</span> <span class="k">as</span> <span class="nn">hl</span>

<span class="n">DEFAULT_REF</span> <span class="o">=</span> <span class="s2">&quot;GRCh38&quot;</span>

<span class="n">hl</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">idempotent</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">quiet</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">skip_logging_configuration</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">default_reference</span><span class="o">=</span><span class="n">DEFAULT_REF</span><span class="p">,</span>
    <span class="n">spark_conf</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;spark.executor.cores&quot;</span><span class="p">:</span> <span class="s2">&quot;4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;spark.driver.memory&quot;</span><span class="p">:</span> <span class="s2">&quot;16g&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>
</code></pre></div>

<p>Notice the <code>DEFAULT_REF</code> variable: it establishes that I intend to use the genomic coordinates considering the Genome Reference Consortium Human Reference 38 (GRCh38), the most recent genome version being accepted by the human genome community. Otherwise Hail would use GRCh37 as default. The <code>spark_conf</code> argument where I setup Spark so it uses four <span class="caps">CPU</span> cores and 16 <span class="caps">GB</span> of <span class="caps">RAM</span>. Change these values as&nbsp;appropriate.</p>
<h2>Importing the <span class="caps">VCF</span>&nbsp;input</h2>
<p>I am now ready to import <code>snp.recalibrated.vcf.gz</code> into the Hail session and convert it to Hail&#8217;s <code>MatrixTable</code> object and write it to the disk. In simple terms, a <code>MatrixTable</code> is a representation of a <span class="caps">VCF</span> file that is amenable to be manipulated by Spark. Read the <a href="https://hail.is/docs/0.2/index.html">Hail Docs</a> for more details. I initiate Hail and then import and convert the dataset with two chained steps (<code>hl.import_vcf().write()</code>):</p>
<div class="highlight"><pre><span></span><code><span class="c1"># hail_demo_import_vcf.py</span>
<span class="kn">import</span> <span class="nn">hail</span> <span class="k">as</span> <span class="nn">hl</span>
<span class="kn">from</span> <span class="nn">hail_demo_init</span> <span class="kn">import</span> <span class="n">DEFAULT_REF</span>

<span class="n">hl</span><span class="o">.</span><span class="n">import_vcf</span><span class="p">(</span><span class="s2">&quot;snp.recalibrated.vcf.gz&quot;</span><span class="p">,</span>
<span class="n">force_bgz</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="n">reference_genome</span><span class="o">=</span><span class="n">DEFAULT_REF</span><span class="p">,</span>
<span class="n">array_elements_required</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;recalibrated.mt&quot;</span><span class="p">,</span><span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>I can now proceed to prepare the dataset for sample and variant quality control (<span class="caps">QC</span>).</p>
<h2>Preparing for Sample <span class="caps">QC</span></h2>
<p>Before reading the created matrix table I create some &#8220;magic numbers&#8221; variables to hold some quality metrics thresholds for sample <span class="caps">QC</span>&nbsp;later:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># hail_demo_sample_qc.py</span>
<span class="kn">import</span> <span class="nn">hail</span> <span class="k">as</span> <span class="nn">hl</span>
<span class="kn">from</span> <span class="nn">hail_demo_init</span> <span class="kn">import</span> <span class="n">DEFAULT_REF</span>

<span class="kn">from</span> <span class="nn">gnomAD.utils.filtering</span> <span class="kn">import</span> <span class="n">filter_to_autosomes</span>
<span class="kn">from</span> <span class="nn">gnomAD.utils.annotations</span> <span class="kn">import</span> <span class="n">add_variant_type</span>

<span class="c1"># Magic numbers</span>
<span class="n">CALL_RATE</span> <span class="o">=</span> <span class="mf">0.90</span>  <span class="c1"># Hail team value = 0.97. gnomAD value = 0.99</span>
<span class="n">RELATEDNESS</span> <span class="o">=</span> <span class="mf">0.088</span>  <span class="c1"># Hail team value. gnomAD value = 0.08838835</span>
<span class="n">READ_DEPTH</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Hail team value.</span>
<span class="n">FREEMIX_CONTAMINATION</span> <span class="o">=</span> <span class="mf">0.05</span>  <span class="c1"># gnomAD value.</span>
<span class="n">CHIMERIC_READS</span> <span class="o">=</span> <span class="mf">0.05</span>  <span class="c1"># gnomAD value.</span>
<span class="n">MEDIAN_LENGTH</span> <span class="o">=</span> <span class="mi">250</span>  <span class="c1"># gnomAD value.</span>
</code></pre></div>

<p>The comment in each line contains the value used by Hail team or gnomAD team. Since this is a demonstration, I may have used different values. Change these values as you feel appropriate as&nbsp;well.</p>
<p>I will now read the matrix table from disk and assign it to the <code>mt</code> object:</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">read_matrix_table</span><span class="p">(</span><span class="s2">&quot;recalibrated.mt&quot;</span><span class="p">)</span>
</code></pre></div>

<p>To check the first few sample ids, I use the <code>show()</code> method (I explain the <code>s</code> here&nbsp;later):</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span><span class="o">.</span><span class="n">s</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<p>To check the matrix table structure, I use the <code>describe()</code> method:</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div>

<p>The output is as&nbsp;follows:</p>
<div class="highlight"><pre><span></span><code>----------------------------------------
Global fields:
    None
----------------------------------------
Column fields:
    &#39;s&#39;: str
----------------------------------------
Row fields:
    &#39;locus&#39;: locus&lt;GRCh38&gt;
    &#39;alleles&#39;: array&lt;str&gt;
    &#39;rsid&#39;: str
    &#39;qual&#39;: float64
    &#39;filters&#39;: set&lt;str&gt;
    &#39;info&#39;: struct {
        AC: array&lt;int32&gt;, 
        AF: array&lt;float64&gt;, 
        AN: int32, 
        BaseQRankSum: float64, 
        DB: bool, 
        DP: int32, 
        END: int32, 
        ExcessHet: float64, 
        FS: float64, 
        FractionInformativeReads: float64, 
        InbreedingCoeff: float64, 
        LOD: float64, 
        MLEAC: array&lt;int32&gt;, 
        MLEAF: array&lt;float64&gt;, 
        MQ: float64, 
        MQRankSum: float64, 
        NEGATIVE_TRAIN_SITE: bool, 
        POSITIVE_TRAIN_SITE: bool, 
        QD: float64, 
        R2_5P_bias: float64, 
        ReadPosRankSum: float64, 
        SOR: float64, 
        VQSLOD: float64, 
        culprit: str
    }
----------------------------------------
Entry fields:
    &#39;AD&#39;: array&lt;int32&gt;
    &#39;AF&#39;: array&lt;float64&gt;
    &#39;DP&#39;: int32
    &#39;F1R2&#39;: array&lt;int32&gt;
    &#39;F2R1&#39;: array&lt;int32&gt;
    &#39;GP&#39;: array&lt;float64&gt;
    &#39;GQ&#39;: int32
    &#39;GT&#39;: call
    &#39;ICNT&#39;: array&lt;int32&gt;
    &#39;MB&#39;: array&lt;int32&gt;
    &#39;MIN_DP&#39;: int32
    &#39;PL&#39;: array&lt;int32&gt;
    &#39;PRI&#39;: array&lt;float64&gt;
    &#39;PS&#39;: int32
    &#39;RGQ&#39;: int32
    &#39;SB&#39;: array&lt;int32&gt;
    &#39;SPL&#39;: array&lt;int32&gt;
    &#39;SQ&#39;: float64
----------------------------------------
Column key: [&#39;s&#39;]
Row key: [&#39;locus&#39;, &#39;alleles&#39;]
----------------------------------------
</code></pre></div>

<p>We can see that a Hail <code>MatrixTable</code> objects has four types of information&nbsp;&#8220;compartments&#8221;:</p>
<ul>
<li>Global fields: information values that are identical for every&nbsp;row</li>
<li>Column fields: sample-level information (id, phenotype, sex&nbsp;etc.)</li>
<li>Row fields: variant-level information (locus, alleles, type of variant, allele frequency&nbsp;etc.)</li>
<li>Entry fields: variant-by-sample-level (genotype, genotype quality,&nbsp;etc.)</li>
</ul>
<p>Also notice that the <code>MatrixTable</code> is keyed by column (<code>s</code>: <strong>s</strong>ample id field) and rows (locus and allele row fields) allowing us to perform <span class="caps">SQL</span>-style table joins. For each field type you can see the name of each field. The info field contains the <span class="caps">INFO</span> field from the input <span class="caps">VCF</span>. The entries fields contain the values listed into the <span class="caps">FORMAT</span> <span class="caps">VCF</span> field. For more details check the <a href="https://hail.is/docs/0.2/tutorials/07-matrixtable.html"><code>MatrixTable</code> Hail Docs</a>.</p>
<p>Now I will modify an entry field and create other row fields that I will need to use later during variant <span class="caps">QC</span>. The commands to create/modify fields is <code>hl.annotate_cols()</code>, <code>hl.annotate_rows()</code> or <code>hl.annotate_entries()</code> depending on the field type (columns, rows, entries, respectively). Notice that in one of them I used a gnomAD&nbsp;function.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Mixture of non-empty with empty PL fields causes problems with sample QC for some reason; setting field to all empty</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_entries</span><span class="p">(</span><span class="n">PL</span><span class="o">=</span><span class="n">hl</span><span class="o">.</span><span class="n">missing</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">PL</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

<span class="c1"># Add variant-level annotations necessary for variant QC later</span>
<span class="c1">## Annotate variants in one of the categories: SNV, multi-SNV, indel, multi-indel, mixed</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span><span class="o">**</span><span class="n">add_variant_type</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">alleles</span><span class="p">))</span> <span class="c1"># gnomAD function</span>

<span class="c1">## Number of alleles at the site</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span><span class="n">n_alleles</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">len</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">alleles</span><span class="p">))</span>

<span class="c1">## Mixed sites (SNVs and indels present at the site)</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span><span class="n">mixed_site</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">if_else</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">variant_type</span> <span class="o">==</span> <span class="s2">&quot;mixed&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>

<span class="c1">## Spanning deletions</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span><span class="n">spanning_deletion</span><span class="o">=</span><span class="n">hl</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">a</span> <span class="o">==</span> <span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">alleles</span><span class="p">))</span>
</code></pre></div>

<p>To check the dimensions of the <code>MatrixTable</code>, I can use the following&nbsp;commands:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Number of Rows, Columns</span>
<span class="n">mt</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

<span class="c1"># Number of Columns</span>
<span class="n">mt</span><span class="o">.</span><span class="n">count_cols</span><span class="p">()</span>
</code></pre></div>

<p>To see a variant breakdown (types, number of variants per chromosome and several other information), there is the following&nbsp;command:</p>
<div class="highlight"><pre><span></span><code><span class="n">hl</span><span class="o">.</span><span class="n">summarize_variants</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span>
</code></pre></div>

<p>A recommended step for further downstream analyses is to split multiallelic variants into biallelic&nbsp;configuration:</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">split_multi_hts</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span>
</code></pre></div>

<p>To remove any monomorphic (invariant) loci I&nbsp;use:</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">n_alleles</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div>

<p>Try the <code>hl.summarize_variants()</code> to check how the numbers changed after&nbsp;splitting.</p>
<p>Up until this moment, I have only genetics-related information into the <code>MatrixTable</code>. I can instruct Hail to import <span class="caps">TSV</span>/<span class="caps">CSV</span> file with sample-level (column) annotations with the <code>hl.import_table()</code> command and then associate each observation by keying the <code>s</code> field with <code>hl.annotate_cols()</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">sa</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">import_table</span><span class="p">(</span><span class="s2">&quot;sample_info.txt&quot;</span><span class="p">,</span> <span class="n">impute</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;s&quot;</span><span class="p">)</span>

<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_cols</span><span class="p">(</span><span class="n">sample_info</span><span class="o">=</span><span class="n">sa</span><span class="p">[</span><span class="n">mt</span><span class="o">.</span><span class="n">s</span><span class="p">])</span>
</code></pre></div>

<p>The <code>sample_info.txt</code> example file has the following&nbsp;format:</p>
<div class="highlight"><pre><span></span><code>s sex phenotype mean_coverage chimeric_reads contamination median_length
sample1 XX case 25 0.02 0.00 300
sample2 XY case 22 0.01 0.00 250
sample3 XY control 30 0.03 0.00 265
sample4 XX control 29 0.01 0.00 250
</code></pre></div>

<p>In this mock sample information file I included the sex karyotype, a fictitious phenotype and sequencing metrics to support the sample <span class="caps">QC</span> procedure. As you may have guessed, any number and type (numeric, string, float, integer, Boolean) of important sample metadata columns can be&nbsp;included.</p>
<p>Whenever we annotate columns, rows or entries in Hail, we must provide the name of the new field. In this case is <code>sample_info</code>. So if I wanted to manipulate, say the sex karyotype field, I would refer the field name this&nbsp;way:</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span><span class="o">.</span><span class="n">sample_info</span><span class="o">.</span><span class="n">sex</span>
</code></pre></div>

<p>This is because the information in the file will be assigned to a dictionary-like field named <code>sample_info</code> within the <code>MatrixTable</code>; the <code>sex</code>, <code>phenotype</code>, etc. fields are <em>inside</em> <code>sample_info</code>.</p>
<h2>Performing Sample <span class="caps">QC</span></h2>
<h3>Plotting quality&nbsp;metrics</h3>
<p>Hail has a very convenient function to calculate descriptive statistics of fields in a <code>MatrixTable</code>:</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">sample_qc</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span>
</code></pre></div>

<p>This function will calculate overall call rate per sample, mean read depth (coverage) and other <a href="https://hail.is/docs/0.2/methods/genetics.html#hail.methods.sample_qc">things</a>. We can plot the calculated fields to assess call rate and coverage (read depth) across samples. The code below will output a <span class="caps">HTML</span> plot to disk (make sure you have the <a href="https://docs.bokeh.org/en/latest/index.html">bokeh</a> Python module&nbsp;installed).</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bokeh.embed</span> <span class="kn">import</span> <span class="n">file_html</span>
<span class="kn">from</span> <span class="nn">bokeh.resources</span> <span class="kn">import</span> <span class="n">CDN</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">mt</span><span class="o">.</span><span class="n">sample_qc</span><span class="o">.</span><span class="n">dp_stats</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">mt</span><span class="o">.</span><span class="n">sample_qc</span><span class="o">.</span><span class="n">call_rate</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Mean DP&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Call Rate&quot;</span><span class="p">,</span>
    <span class="n">hover_fields</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ID&quot;</span><span class="p">:</span> <span class="n">mt</span><span class="o">.</span><span class="n">s</span><span class="p">},</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">html</span> <span class="o">=</span> <span class="n">file_html</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">CDN</span><span class="p">,</span> <span class="s2">&quot;Chart&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;Call Rate by Mean DP.html&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">html</span><span class="p">)</span>
</code></pre></div>

<h3>Filter samples by quality&nbsp;thresholds</h3>
<p>I can finally filter out samples that do not meet the quality thresholds I established before. For example, the lines below will keep only samples that meet overall call rate and mean coverage quality&nbsp;criteria:</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">filter_cols</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">sample_qc</span><span class="o">.</span><span class="n">call_rate</span> <span class="o">&gt;=</span> <span class="n">CALL_RATE</span><span class="p">)</span>

<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">filter_cols</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">sample_qc</span><span class="o">.</span><span class="n">dp_stats</span><span class="o">.</span><span class="n">mean</span> <span class="o">&gt;=</span> <span class="n">READ_DEPTH</span><span class="p">)</span>
</code></pre></div>

<p>If you have other quality criteria, you could filter in a similar way by correctly referring the field name (remember that dictionary-like fields contain other fields, as is the case of <code>sample_info</code> I mentioned earlier and <code>sample_qc</code> above) and a logical expression (which must follow the Python syntax for equalities and&nbsp;inequalities).</p>
<h3>Principal component analysis (<span class="caps">PCA</span>) to filter related&nbsp;samples</h3>
<p>To ensure that each sample in the cohort is unrelated to any other sample, we can run a principal component analysis (<span class="caps">PCA</span>) to evidence samples with kinship too higher according to our chosen threshold. The <span class="caps">PCA</span> will only work with autosome (diploid) biallelic variants. The code below will filter our <code>MatrixTable</code> keeping only variants meeting these&nbsp;conditions:</p>
<div class="highlight"><pre><span></span><code><span class="n">for_pca</span> <span class="o">=</span> <span class="n">filter_to_autosomes</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span> <span class="c1"># gnomAD function. Will keep variants in chromosomes 1 to 22 only.</span>
<span class="n">for_pca</span> <span class="o">=</span> <span class="n">for_pca</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span><span class="n">for_pca</span><span class="o">.</span><span class="n">n_alleles</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># will remove sites that were multi-allelic before splitting as well to ensure &quot;pure&quot; biallelic sites</span>
</code></pre></div>

<p>Then, I determine the sample number to calculate <code>k</code>, the number of principal&nbsp;components.</p>
<div class="highlight"><pre><span></span><code><span class="n">sample_num</span> <span class="o">=</span> <span class="n">for_pca</span><span class="o">.</span><span class="n">cols</span><span class="p">()</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</code></pre></div>

<p>Next, using the <a href="https://hail.is/docs/0.2/methods/genetics.html#hail.methods.hwe_normalized_pca"><code>hl.hwe_normalized_pca()</code> function</a> I calculate the principal component&nbsp;scores:</p>
<div class="highlight"><pre><span></span><code><span class="n">_</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">hwe_normalized_pca</span><span class="p">(</span>
    <span class="n">for_pca</span><span class="o">.</span><span class="n">GT</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">sample_num</span> <span class="o">//</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="n">compute_loadings</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>With big sample sizes, the code above will restrict <code>k</code> to the maximum of 10 principal&nbsp;components.</p>
<p>The scores are one of the inputs of the <a href="https://hail.is/docs/0.2/methods/relatedness.html#hail.methods.pc_relate"><code>hl.pc_relate()</code> function</a> that will estimate the relatedness between samples in a pairwise manner. To speed things up, I will estimate only the kinship statistic (<code>statistics="kin"</code>, while the default is <code>statistics="all"</code>. Check the function documentation in the previous link for more&nbsp;details).</p>
<div class="highlight"><pre><span></span><code><span class="n">relatedness_ht</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">pc_relate</span><span class="p">(</span>
    <span class="n">for_pca</span><span class="o">.</span><span class="n">GT</span><span class="p">,</span>
    <span class="n">min_individual_maf</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">scores_expr</span><span class="o">=</span><span class="n">scores</span><span class="p">[</span><span class="n">for_pca</span><span class="o">.</span><span class="n">col_key</span><span class="p">]</span><span class="o">.</span><span class="n">scores</span><span class="p">,</span>
    <span class="n">block_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
    <span class="n">min_kinship</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">statistics</span><span class="o">=</span><span class="s2">&quot;kin&quot;</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

<p>The <code>relatedness_ht</code> object is a Hail <code>Table</code>. It differs from a <code>MatrixTable</code> by not having column nor entries fields. We determine related samples by filtering this table to keep only the samples above the kinship threshold and then passing the object to <a href="https://hail.is/docs/0.2/methods/misc.html#hail.methods.maximal_independent_set"><code>hl.maximal_independent_set()</code> function</a>:</p>
<div class="highlight"><pre><span></span><code><span class="n">pairs</span> <span class="o">=</span> <span class="n">relatedness_ht</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">relatedness_ht</span><span class="p">[</span><span class="s2">&quot;kin&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">RELATEDNESS</span><span class="p">)</span>

<span class="n">related_samples_to_remove</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">maximal_independent_set</span><span class="p">(</span><span class="n">pairs</span><span class="o">.</span><span class="n">i</span><span class="p">,</span> <span class="n">pairs</span><span class="o">.</span><span class="n">j</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<p>The <code>related_samples_to_remove</code> object will contain a selection of samples to be removed from the dataset because they come from related individuals in the sample. We perform this filtering with the command below. Notice the use of the keyword <code>keep=False</code> to <em>negate</em> the selection (I do <em>not</em> want to keep related&nbsp;samples).</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">filter_cols</span><span class="p">(</span><span class="n">hl</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="n">related_samples_to_remove</span><span class="p">[</span><span class="n">mt</span><span class="o">.</span><span class="n">col_key</span><span class="p">]),</span> <span class="n">keep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<p>Use <code>mt.count_cols()</code> to assess if any sample was&nbsp;removed.</p>
<h3>Wrapping up the sample <span class="caps">QC</span></h3>
<p>Here I finish the sample <span class="caps">QC</span> process. I then save the <code>relatedness_ht</code> and the dataset object <code>mt</code> to disk with <code>write()</code>:</p>
<div class="highlight"><pre><span></span><code><span class="n">relatedness_ht</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;relatedness.ht&quot;</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">mt</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;sampleqc_pass.mt&quot;</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>I can now proceed to variant <span class="caps">QC</span>.</p>
<h2>Variant <span class="caps">QC</span></h2>
<p>I init Hail again if needed, import some more functions from gnomAD, create variables with variant quality thresholds, read the <code>MatrixTable</code> with the data passing sample <span class="caps">QC</span> and calculate common variant statistics (such as allelic frequency) with <a href="https://hail.is/docs/0.2/methods/genetics.html#hail.methods.variant_qc"><code>hl.variant_qc()</code></a>:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># hail_demo_variant_qc.py</span>
<span class="c1"># Import modules and init Hail</span>
<span class="kn">import</span> <span class="nn">hail</span> <span class="k">as</span> <span class="nn">hl</span>

<span class="kn">from</span> <span class="nn">gnomAD.utils.annotations</span> <span class="kn">import</span> <span class="n">bi_allelic_site_inbreeding_expr</span>
<span class="kn">from</span> <span class="nn">gnomAD.variant_qc.random_forest</span> <span class="kn">import</span> <span class="n">apply_rf_model</span><span class="p">,</span> <span class="n">median_impute_features</span>
<span class="kn">from</span> <span class="nn">gnomAD.variant_qc.pipeline</span> <span class="kn">import</span> <span class="n">train_rf_model</span>
<span class="kn">from</span> <span class="nn">hail_init</span> <span class="kn">import</span> <span class="n">DEFAULT_REF</span>

<span class="c1"># Variant Quality hard filters</span>
<span class="n">INBR_COEFF</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.3</span>
<span class="n">AB_LOWER_LIM</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">AB_UPPER_LIM</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">AB_LOWER_LIM</span>

<span class="c1"># Read MatrixTable with sample QC-passing dataset</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">read_matrix_table</span><span class="p">(</span><span class="s2">&quot;sampleqc_pass.mt&quot;</span><span class="p">)</span>

<span class="n">mt</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">variant_qc</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span>
</code></pre></div>

<p>Even though allelic frequency may be already been lift over from the original <span class="caps">VCF</span> input, I recommend using <code>hl.variant_qc()</code> since it calculates potentially useful information besides allelic frequency, such as p-values from the test of Hardy-Weinberg equilibrium. Check the function documentation at Hail to see the complete list of&nbsp;statistics.</p>
<h3>Filter variants by genotype-related quality&nbsp;thresholds</h3>
<p>Next, I calculate two variant-level metrics: inbreeding coefficient and the maximum p-value for sampling the observed allele balance under a binomial&nbsp;model.</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span><span class="n">inbr_coeff</span><span class="o">=</span><span class="n">bi_allelic_site_inbreeding_expr</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">GT</span><span class="p">))</span>

<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span>
    <span class="n">pab_max</span><span class="o">=</span><span class="n">hl</span><span class="o">.</span><span class="n">agg</span><span class="o">.</span><span class="n">max</span><span class="p">(</span>
        <span class="n">hl</span><span class="o">.</span><span class="n">binom_test</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">AD</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">mt</span><span class="o">.</span><span class="n">DP</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;two-sided&quot;</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

<p>Next, I remove variants with excess of heterozygotes by inbreeding coefficient and variants for which no sample had high-quality genotypes by evaluating allele balance (the proportion of sequencing reads that support the&nbsp;variant):</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">inbr_coeff</span> <span class="o">&gt;</span> <span class="n">INBR_COEFF</span><span class="p">)</span>

<span class="c1"># Removing variants for which no sample had high quality genotypes with hl.any()</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span><span class="n">hl</span><span class="o">.</span><span class="n">agg</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">GQ</span> <span class="o">&gt;=</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span><span class="n">hl</span><span class="o">.</span><span class="n">agg</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">DP</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_entries</span><span class="p">(</span><span class="n">AB</span><span class="o">=</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">AD</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">hl</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">AD</span><span class="p">)))</span> <span class="c1"># AB = allele balance</span>

<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span>
    <span class="n">hl</span><span class="o">.</span><span class="n">agg</span><span class="o">.</span><span class="n">any</span><span class="p">(</span>
        <span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">GT</span><span class="o">.</span><span class="n">is_hom_ref</span><span class="p">()</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">AB</span> <span class="o">&lt;</span> <span class="n">AB_LOWER_LIM</span><span class="p">))</span>
        <span class="o">|</span> <span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">GT</span><span class="o">.</span><span class="n">is_het</span><span class="p">()</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">AB</span> <span class="o">&gt;=</span> <span class="n">AB_LOWER_LIM</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">AB</span> <span class="o">&lt;=</span> <span class="n">AB_UPPER_LIM</span><span class="p">))</span>
        <span class="o">|</span> <span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">GT</span><span class="o">.</span><span class="n">is_hom_var</span><span class="p">()</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">AB</span> <span class="o">&gt;</span> <span class="n">AB_UPPER_LIM</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div>

<h3>Variant <span class="caps">QC</span> by random forest&nbsp;model</h3>
<p>The gnomAD team adopted a <a href="https://gnomAD.broadinstitute.org/news/2018-10-gnomAD-v2-1/">random forest model</a> to filter out sequencing artifacts. Briefly, they labelled variants passing quality thresholds (such as <span class="caps">GATK</span>&#8217;s <span class="caps">VQSR</span>) as true positives and variants not passing as false positives. Next, they performed a supervised random forest training with some variant-level features. From now on, I try to replicate their method with the best of my&nbsp;understanding.</p>
<p>I label the variants as true and false&nbsp;positives:</p>
<div class="highlight"><pre><span></span><code><span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span><span class="n">tp</span><span class="o">=</span><span class="n">hl</span><span class="o">.</span><span class="n">if_else</span><span class="p">(</span><span class="n">hl</span><span class="o">.</span><span class="n">len</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">filters</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span><span class="n">fp</span><span class="o">=</span><span class="n">hl</span><span class="o">.</span><span class="n">if_else</span><span class="p">(</span><span class="n">hl</span><span class="o">.</span><span class="n">len</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">filters</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</code></pre></div>

<p>The logic is that if the <code>filters</code> field (which is carried over from the GenomicsDB-exported <span class="caps">VCF</span>) is empty, it indicates the variant passed the <span class="caps">VQSR</span> filter and is a false positive otherwise. Thus, I create two Boolean-type columns indicating it. Next, I create a Hail <code>Table</code> extracting the needed features and the <code>tp</code> and <code>fp</code> fields and assigning it to the <code>rf_ht</code> object:</p>
<div class="highlight"><pre><span></span><code><span class="n">rf_ht</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">select_rows</span><span class="p">(</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">inbr_coeff</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">SOR</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">ReadPosRankSum</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">MQRankSum</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">QD</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">pab_max</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">variant_type</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">n_alleles</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">mixed_site</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">spanning_deletion</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">tp</span><span class="p">,</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">fp</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">rows</span><span class="p">()</span>
</code></pre></div>

<p>Remember that most of these features are brought over from the <span class="caps">VCF</span> <span class="caps">INFO</span> field, while the others were generated with the help of Hail. I also generate a Python list with the features&nbsp;names:</p>
<div class="highlight"><pre><span></span><code><span class="n">features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;inbr_coeff&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SOR&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ReadPosRankSum&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MQRankSum&quot;</span><span class="p">,</span>
    <span class="s2">&quot;QD&quot;</span><span class="p">,</span>
    <span class="s2">&quot;pab_max&quot;</span><span class="p">,</span>
    <span class="s2">&quot;variant_type&quot;</span><span class="p">,</span>
    <span class="s2">&quot;n_alleles&quot;</span><span class="p">,</span>
    <span class="s2">&quot;mixed_site&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spanning_deletion&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p>Since random forest models do not tolerate missing data, I use a gnomAD function to impute any missing data with the median of the&nbsp;field:</p>
<div class="highlight"><pre><span></span><code><span class="n">rf_ht</span> <span class="o">=</span> <span class="n">median_impute_features</span><span class="p">(</span><span class="n">rf_ht</span><span class="p">)</span>
</code></pre></div>

<p>I will reserve all variants located in chromosome 20 to perform model evaluation with the help of the <a href="https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.parse_locus_interval"><code>hl.parse_locus_interval()</code> function</a>:</p>
<div class="highlight"><pre><span></span><code><span class="n">test_intervals</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;chr20&quot;</span><span class="p">]</span>

<span class="n">test_intervals</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">hl</span><span class="o">.</span><span class="n">parse_locus_interval</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reference_genome</span><span class="o">=</span><span class="s2">&quot;GRCh38&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">test_intervals</span>
<span class="p">]</span>
</code></pre></div>

<p>I now may train the model with the help of gnomAD&#8217;s <code>train_rf_model()</code> function. Internally, the function will select a balanced dataset of true positives and false positives to train the&nbsp;model.</p>
<div class="highlight"><pre><span></span><code><span class="n">rf_trained_ht</span><span class="p">,</span> <span class="n">rf_model</span> <span class="o">=</span> <span class="n">train_rf_model</span><span class="p">(</span>
    <span class="n">rf_ht</span><span class="p">,</span>
    <span class="n">rf_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
    <span class="n">tp_expr</span><span class="o">=</span><span class="n">rf_ht</span><span class="o">.</span><span class="n">tp</span><span class="p">,</span>
    <span class="n">fp_expr</span><span class="o">=</span><span class="n">rf_ht</span><span class="o">.</span><span class="n">fp</span><span class="p">,</span>
    <span class="n">test_expr</span><span class="o">=</span><span class="n">hl</span><span class="o">.</span><span class="n">literal</span><span class="p">(</span><span class="n">test_intervals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">interval</span><span class="p">:</span> <span class="n">interval</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">rf_ht</span><span class="o">.</span><span class="n">locus</span><span class="p">)</span>
    <span class="p">),</span>
<span class="p">)</span>
</code></pre></div>

<p>The <code>rf_trained_ht</code> output is a Hail <code>Table</code> with annotations related with the random forest model training. The <code>rf_model</code> object is the model binary generated by Spark. The inputs include the <code>rf_ht Table</code>, the <code>features</code> list, the <code>rf_ht.tp</code> and <code>rf_ht.fp</code> Boolean columns and a <code>test_expr</code> argument receives a expression that will ensure that the loci contained in the interval object <code>test_intervals</code> will be used for model&nbsp;evaluation.</p>
<p>After model training, I left join the <code>rf_ht</code> with the model-annotated <code>rf_trained_ht</code> into the <code>ht Table</code>. I use it as the input for the gnomAD&#8217;s <code>apply_rf_model()</code> function. It will apply the random forest model in all variants in the genome, including those not selected for&nbsp;training.</p>
<div class="highlight"><pre><span></span><code><span class="n">ht</span> <span class="o">=</span> <span class="n">rf_ht</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">rf_trained_ht</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>

<span class="n">rf_results</span> <span class="o">=</span> <span class="n">apply_rf_model</span><span class="p">(</span>
    <span class="n">ht</span><span class="o">=</span><span class="n">ht</span><span class="p">,</span>
    <span class="n">rf_model</span><span class="o">=</span><span class="n">rf_model</span><span class="p">,</span>
    <span class="n">features</span><span class="o">=</span><span class="n">hl</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">rf_trained_ht</span><span class="o">.</span><span class="n">features</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;rf_label&quot;</span><span class="p">,</span>
    <span class="n">prediction_col_name</span><span class="o">=</span><span class="s2">&quot;rf_prediction&quot;</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

<p>I then write to disk the Hail <code>Table</code> containing a summary of the number of variants originally labeled as true or false positives and the prediction by the model. In other words - a confusion&nbsp;matrix:</p>
<div class="highlight"><pre><span></span><code><span class="n">rf_summary_ht</span> <span class="o">=</span> <span class="n">rf_results</span><span class="o">.</span><span class="n">group_by</span><span class="p">(</span>
    <span class="s2">&quot;tp&quot;</span><span class="p">,</span> <span class="s2">&quot;fp&quot;</span><span class="p">,</span> <span class="s2">&quot;rf_train&quot;</span><span class="p">,</span> <span class="s2">&quot;rf_label&quot;</span><span class="p">,</span> <span class="s2">&quot;rf_prediction&quot;</span>
<span class="p">)</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">hl</span><span class="o">.</span><span class="n">agg</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>

<span class="n">rf_summary_ht</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;rf_summary.ht&quot;</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>I unpack the <code>rf_results Table</code> fields and join them in the sample <span class="caps">QC</span> <code>MatrixTable</code>:</p>
<div class="highlight"><pre><span></span><code><span class="n">variantqc_pass</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">annotate_rows</span><span class="p">(</span><span class="o">**</span><span class="n">rf_results</span><span class="p">[</span><span class="n">mt</span><span class="o">.</span><span class="n">locus</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">alleles</span><span class="p">])</span>
</code></pre></div>

<p>It can be easily filtered to keep only variants predicted to be true positives by the model and then written to&nbsp;disk:</p>
<div class="highlight"><pre><span></span><code><span class="n">variantqc_pass</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span><span class="n">variantqc_pass</span><span class="o">.</span><span class="n">rf_prediction</span> <span class="o">==</span> <span class="s2">&quot;TP&quot;</span><span class="p">)</span>

<span class="n">variantqc_pass</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;variantqc_pass.mt&quot;</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h2>Filter loci by coordinates or allelic&nbsp;frequency</h2>
<p>Now the dataset has passed all <span class="caps">QC</span>, I may query it to search for new variants or answer other scientific questions. To illustrate that, I will filter the dataset to contain variants in delimited regions of the genome with a certain range of allelic frequencies. To parse specific regions from a genome, I can create a Python list of strings representing exact or approximate&nbsp;coordinates:</p>
<div class="highlight"><pre><span></span><code><span class="n">intervals</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;chr10:52765380-52772784&quot;</span><span class="p">,</span> <span class="s2">&quot;chr1:100M-200M&quot;</span><span class="p">]</span>
</code></pre></div>

<p>Now I will apply the filter to a <code>MatrixTable</code> with <code>hl.parse_locus_interval()</code>:</p>
<div class="highlight"><pre><span></span><code><span class="n">filtered_mt</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">filter_intervals</span><span class="p">(</span>
    <span class="n">variantqc_pass</span><span class="p">,</span>
    <span class="p">[</span><span class="n">hl</span><span class="o">.</span><span class="n">parse_locus_interval</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reference_genome</span><span class="o">=</span><span class="n">DEFAULT_REF</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">intervals</span><span class="p">])</span> 
</code></pre></div>

<p>I can also pinpoint an individual locus and create a window of nucleotides before and after it. In the code below I create a window of 100,000 nucleotides before and after a specific position in chromosome&nbsp;X.</p>
<div class="highlight"><pre><span></span><code><span class="n">locus</span> <span class="o">=</span> <span class="n">hl</span><span class="o">.</span><span class="n">parse_locus</span><span class="p">(</span><span class="s2">&quot;chrX:23833353&quot;</span><span class="p">,</span> <span class="n">DEFAULT_REF</span><span class="p">)</span>
<span class="n">window</span> <span class="o">=</span> <span class="n">locus</span><span class="o">.</span><span class="n">window</span><span class="p">(</span><span class="mi">100000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>

<span class="n">filtered_mt</span> <span class="o">=</span> <span class="n">variantqc_pass</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span><span class="n">window</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">variantqc_pass</span><span class="o">.</span><span class="n">locus</span><span class="p">))</span>
</code></pre></div>

<p>If I wanted to check the first few genotypes of the filtered <code>MatrixTable</code> by the specified window I would use the command&nbsp;below:</p>
<div class="highlight"><pre><span></span><code><span class="n">filtered_mt</span><span class="o">.</span><span class="n">GT</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<p>Since this coordinate is not on the pseudoautosomal region (<span class="caps">PAR</span>) of the X chromosomes, karyotypically normal male individuals will be haploid around this region, and Hail would correctly show only one allele instead of two in the <code>GT</code> call.</p>
<p>Since I used <code>hl.variant_qc()</code> at the beginning of variant <span class="caps">QC</span>, I may filter the variants by their allelic frequency. For example, If I wanted to keep only the variants with less than 1% frequency I would&nbsp;do:</p>
<div class="highlight"><pre><span></span><code><span class="n">filtered_mt</span> <span class="o">=</span> <span class="n">filtered_mt</span><span class="o">.</span><span class="n">filter_rows</span><span class="p">(</span><span class="n">filtered_mt</span><span class="o">.</span><span class="n">variant_qc</span><span class="o">.</span><span class="n">AF</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">)</span>
</code></pre></div>

<p>Remember to <code>write()</code> the <code>MatrixTable</code> if you want to save the dataset with any applied&nbsp;filters.</p>
<h2>Conclusion</h2>
<p>In this post&nbsp;I:</p>
<ul>
<li>Introduced the Hail&nbsp;framework;</li>
<li>Mentioned software used for preparing multi-sample <span class="caps">VCF</span> input starting with multiple gVCF&nbsp;files;</li>
<li>Demonstrated how to perform sample and variant <span class="caps">QC</span> with&nbsp;Hail;</li>
<li>Demonstrated how filter dataset according to quality metrics, locus or loci&nbsp;interval.</li>
</ul>
<h2>Acknowledgements</h2>
<p>This demonstration was made possible with the help of by insights acquired by reading through&nbsp;the:</p>
<ul>
<li><a href="https://discuss.hail.is/">Hail Discussion Forum</a>&nbsp;posts;</li>
<li><a href="https://github.com/populationgenomics/joint-calling">Centre for Population Genomics GitHub repository</a>;</li>
<li><a href="https://github.com/broadinstitute/gnomad_methods">gnomADs&#8217; utilities GitHub repository</a>;</li>
<li>gnomAD team&#8217;s supplementary material from their <a href="https://www.nature.com/articles/s41586-020-2308-7">2020 Nature paper</a>.</li>
</ul>
<h2>Appendix</h2>
<p>In this post I gave general directions how to combine multiple gVCF files into one single <span class="caps">VCF</span> input. Hail actually has an experimental function that has this very purpose: <a href="https://hail.is/docs/0.2/experimental/vcf_combiner.html"><code>hl.experimental.run_combiner()</code></a>. However, I tried to use this function and had problems with it. It generates a &#8220;sparse&#8221; <code>MatrixTable</code> and unfortunately I found the function documentation insufficiently clear on how to work with this slightly different form of intermediate input, so I resorted to <span class="caps">GATK</span>&#8217;s <code>GenomicsDBImport</code> as stated. Since Hail is in active development, I expect improvement on both the function and on its&nbsp;documentation.</p>
<p>Throughout the demonstration I used <code>write()</code> method to write <code>MatrixTable</code>s to disk and later read them back into the session with <code>read_matrix_table()</code>. Alternatively I could have used Hail&#8217;s <code>checkpoint()</code> method as an alias for these sequential operations. Read the documentation <a href="https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.checkpoint">here</a>.</p>
<p><em>Subscribe to my <a href="https://antoniocampos13.github.io/feeds/all.rss.xml"><span class="caps">RSS</span> feed</a>, <a href="https://antoniocampos13.github.io/feeds/all.atom.xml">Atom feed</a> or <a href="https://t.me/joinchat/AAAAAEYrNCLK80Fh1w8nAg">Telegram channel</a> to keep you updated whenever I post new&nbsp;content.</em></p>
<h2>References</h2>
<p><a href="https://www.einstein.br/Pages/Home.aspx">Hospital Israelita Albert&nbsp;Einstein</a></p>
<p><a href="https://hail.is/">Hail |&nbsp;Index</a></p>
<p><a href="https://www.broadinstitute.org/">Broad&nbsp;Institute</a></p>
<p><a href="https://gnomAD.broadinstitute.org/">gnomAD</a></p>
<p><a href="https://hail.is/#install">Hail |&nbsp;Index</a></p>
<p><a href="https://pypi.org/project/gnomAD/">gnomAD module |&nbsp;PyPi</a></p>
<p><a href="https://gatk.broadinstitute.org/hc/en-us">Genomic Analysis&nbsp;Toolkit</a></p>
<p><a href="http://samtools.github.io/bcftools/bcftools.html">bcftools</a></p>
<p><a href="https://antoniocampos13.github.io/setting-up-your-unix-computer-for-bioinformatics-analysis.html">Setting Up Your Unix Computer for Bioinformatics&nbsp;Analysis</a></p>
<p><a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035531812-GVCF-Genomic-Variant-Call-Format">Genomic Variant Call Format&nbsp;(gVCF)</a></p>
<p><a href="https://www.illumina.com/products/by-type/informatics-products/dragen-bio-it-platform.html">Illumina <span class="caps">DRAGEN</span> Bio-<span class="caps">IT</span> Platform| Variant calling <span class="amp">&amp;</span> secondary genomic analysis software&nbsp;tool</a></p>
<p><a href="https://samtools.github.io/hts-specs/VCFv4.2.pdf">Variant Call Format specification | version&nbsp;4.2</a></p>
<p><a href="https://gatk.broadinstitute.org/hc/en-us/articles/360036883491-GenomicsDBImport"><span class="caps">GATK</span> |&nbsp;GenomicsDBImport</a></p>
<p><a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035531112--How-to-Filter-variants-either-with-VQSR-or-by-hard-filtering"><span class="caps">GATK</span> | Variant Qualit Score Recalibration (<span class="caps">VQSR</span>)</a></p>
<p><a href="https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=&amp;forceOnObjectsSortingFiltering=false"><span class="caps">GATK</span> Resource Bundle at Google&nbsp;Cloud</a></p>
<p><a href="https://cloud.google.com/storage/docs/gsutil">gsutil tool | Google&nbsp;Cloud</a></p>
<p><a href="https://hail.is/docs/0.2/index.html">Hail | Hail&nbsp;0.2</a></p>
<p><a href="https://hail.is/docs/0.2/tutorials/07-matrixtable.html">Hail | MatrixTable&nbsp;Tutorial</a></p>
<p><a href="https://hail.is/docs/0.2/methods/genetics.html#hail.methods.sample_qc">Hail | Genetics |&nbsp;sample_qc</a></p>
<p><a href="https://docs.bokeh.org/en/latest/index.html">Bokeh&nbsp;documentation</a></p>
<p><a href="https://hail.is/docs/0.2/methods/genetics.html#hail.methods.hwe_normalized_pca">Hail | Genetics |&nbsp;hwe_normalized_pca</a></p>
<p><a href="https://hail.is/docs/0.2/methods/relatedness.html#hail.methods.pc_relate">Hail |&nbsp;Relatedness</a></p>
<p><a href="https://hail.is/docs/0.2/methods/misc.html#hail.methods.maximal_independent_set">Hail |&nbsp;Miscellaneous</a></p>
<p><a href="https://hail.is/docs/0.2/methods/genetics.html#hail.methods.variant_qc">Hail | Genetics |&nbsp;variant_qc</a></p>
<p><a href="https://gnomAD.broadinstitute.org/news/2018-10-gnomAD-v2-1/">gnomAD v2.1 | gnomAD&nbsp;news</a></p>
<p><a href="https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.parse_locus_interval">Hail | Genetics&nbsp;functions</a></p>
<p><a href="https://discuss.hail.is/">Hail&nbsp;Discussion</a></p>
<p><a href="https://github.com/populationgenomics/joint-calling">Centre for Population Genomics GitHub&nbsp;repository</a></p>
<p><a href="https://github.com/broadinstitute/gnomad_methods">gnomADs&#8217; utilities GitHub&nbsp;repository</a></p>
<p><a href="https://www.nature.com/articles/s41586-020-2308-7">The mutational constraint spectrum quantified from variation in 141,456&nbsp;humans</a></p>
<p><a href="https://hail.is/docs/0.2/experimental/vcf_combiner.html">Hail | <span class="caps">VCF</span>&nbsp;Combiner</a></p>
<p><a href="https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.checkpoint">Hail | MatrixTable |&nbsp;checkpoint</a></p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://antoniocampos13.github.io/tag/bioinformatics.html">Bioinformatics</a>
      <a href="https://antoniocampos13.github.io/tag/genomics.html">Genomics</a>
      <a href="https://antoniocampos13.github.io/tag/hail.html">Hail</a>
    </p>
  </div>





</article>

    <footer>
<p>
  &copy; 2020 Antonio Victor Campos Coelho - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
           src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Antonio's Portfolio ",
  "url" : "https://antoniocampos13.github.io",
  "image": "https://avatars.githubusercontent.com/antoniocampos13",
  "description": "Data Science Portfolio by Antonio Victor Campos Coelho"
}
</script>

</body>
</html>