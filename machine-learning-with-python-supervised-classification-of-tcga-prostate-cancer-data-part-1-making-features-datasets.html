
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://antoniocampos13.github.io/theme/stylesheet/style.min.css">


    <link id="pygments-light-theme" rel="stylesheet" type="text/css"
          href="https://antoniocampos13.github.io/theme/pygments/vs.min.css">


  <link rel="stylesheet" type="text/css" href="https://antoniocampos13.github.io/theme/font-awesome/css/fontawesome.css">
  <link rel="stylesheet" type="text/css" href="https://antoniocampos13.github.io/theme/font-awesome/css/brands.css">
  <link rel="stylesheet" type="text/css" href="https://antoniocampos13.github.io/theme/font-awesome/css/solid.css">


    <link href="https://antoniocampos13.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Antonio's Portfolio Atom">

    <link href="https://antoniocampos13.github.io/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Antonio's Portfolio RSS">



    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#333333">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#333333">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Microsoft EDGE -->
    <meta name="msapplication-TileColor" content="#333333">

<meta name="author" content="Antonio Victor Campos Coelho" />
<meta name="description" content="Introduction In a previous post, I showed how to retrieve The Cancer Genome Atlas (TCGA) data from the Cancer Genomics Cloud (CGC) platform. I downloaded gene expression quantification data, created a relational database with PostgreSQL, and created a dataset uniting the raw quantification data for 675 differentially expressed genes identified …" />
<meta name="keywords" content="Bioinformatics, gene expression, machine learning, supervised classification">


<meta property="og:site_name" content="Antonio's Portfolio"/>
<meta property="og:title" content="Machine Learning with Python: Supervised Classification of TCGA Prostate Cancer Data (Part 1 - Making Features Datasets)"/>
<meta property="og:description" content="Introduction In a previous post, I showed how to retrieve The Cancer Genome Atlas (TCGA) data from the Cancer Genomics Cloud (CGC) platform. I downloaded gene expression quantification data, created a relational database with PostgreSQL, and created a dataset uniting the raw quantification data for 675 differentially expressed genes identified …"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://antoniocampos13.github.io/machine-learning-with-python-supervised-classification-of-tcga-prostate-cancer-data-part-1-making-features-datasets.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-11-05 14:50:00-03:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://antoniocampos13.github.io/author/antonio-victor-campos-coelho.html">
<meta property="article:section" content="Python"/>
<meta property="article:tag" content="Bioinformatics"/>
<meta property="article:tag" content="gene expression"/>
<meta property="article:tag" content="machine learning"/>
<meta property="article:tag" content="supervised classification"/>
<meta property="og:image" content="https://avatars.githubusercontent.com/antoniocampos13">

  <title>Antonio's Portfolio &ndash; Machine Learning with Python: Supervised Classification of TCGA Prostate Cancer Data (Part 1 - Making Features Datasets)</title>

</head>
<body class="light-theme">
  <aside>
    <div>
      <a href="https://antoniocampos13.github.io">
        <img src="https://avatars.githubusercontent.com/antoniocampos13" alt="Antonio's Portfolio" title="Antonio's Portfolio">
      </a>

      <h1>
        <a href="https://antoniocampos13.github.io">Antonio's Portfolio</a>
      </h1>

<p>PhD in Genetics</p>

      <nav>
        <ul class="list">


              <li>
                <a target="_self"
                   href="https://antoniocampos13.github.io/pages/about.html#about">
                  About
                </a>
              </li>
              <li>
                <a target="_self"
                   href="https://antoniocampos13.github.io/pages/contact.html#contact">
                  Contact
                </a>
              </li>

            <li>
              <a target="_self" href="http://lattes.cnpq.br/2986394950644755" >Brazilian Lattes CV</a>
            </li>
            <li>
              <a target="_self" href="https://scholar.google.com.br/citations?user=d2ij4wUAAAAJ&hl" >Google Scholar</a>
            </li>
            <li>
              <a target="_self" href="https://orcid.org/0000-0003-2143-9701" >ORCID</a>
            </li>
            <li>
              <a target="_self" href="https://publons.com/researcher/2414076/antonio-victor-c-coelho" >Researcher ID/Publons</a>
            </li>
        </ul>
      </nav>

      <ul class="social">
          <li>
            <a  class="sc-github" href="https://github.com/antoniocampos13/portfolio" target="_blank">
              <i class="fab fa-github"></i>
            </a>
          </li>
          <li>
            <a  class="sc-linkedin" href="https://www.linkedin.com/in/antonio-coelho-9aa338164" target="_blank">
              <i class="fab fa-linkedin"></i>
            </a>
          </li>
      </ul>
    </div>

  </aside>
  <main>

    <nav>
      <a href="https://antoniocampos13.github.io">Home</a>

      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>

      <a href="https://antoniocampos13.github.io/feeds/all.atom.xml">Atom</a>

      <a href="https://antoniocampos13.github.io/feeds/all.rss.xml">RSS</a>
    </nav>

<article class="single">
  <header>
      
    <h1 id="machine-learning-with-python-supervised-classification-of-tcga-prostate-cancer-data-part-1-making-features-datasets">Machine Learning with Python: Supervised Classification of <span class="caps">TCGA</span> Prostate Cancer Data (Part 1 - Making Features&nbsp;Datasets)</h1>
    <p>
      Posted on Thu 05 November 2020 in <a href="https://antoniocampos13.github.io/category/python.html">Python</a>

    </p>
  </header>


  <div>
    <h2>Introduction</h2>
<p>In a <a href="https://antoniocampos13.github.io/working-with-cancer-genomics-cloud-datasets-in-a-postgresql-database-part-1.html">previous post</a>, I showed how to retrieve <a href="https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga">The Cancer Genome Atlas (<span class="caps">TCGA</span>)</a> data from the <a href="http://www.cancergenomicscloud.org/">Cancer Genomics Cloud (<span class="caps">CGC</span>) platform</a>. I downloaded gene expression quantification data, created a relational database with PostgreSQL, and created a dataset uniting the raw quantification data for 675 differentially expressed genes <a href="https://antoniocampos13.github.io/differential-expression-analysis-with-edger-in-r.html#differential-expression-analysis-with-edger-in-r">identified by edgeR</a>, race, age at diagnosis and tumor size at&nbsp;diagnosis.</p>
<p>In this post, I will use Python to prepare features datasets to use them to produce a classification model using machine learning tools, especially the <code>scikit-learn</code> module. Check its documentation <a href="https://scikit-learn.org/stable/">here</a>.</p>
<p>The dataset and code presented here are available in my <a href="https://github.com/antoniocampos13/portfolio/tree/master/Python/2020_11_05_Supervised_Machine_Leaning_TCGA_Data">portfolio</a>.</p>
<h2>Prepare&nbsp;workspace</h2>
<p>Since I will generate a statistical model, it is important to test it in never-seen before data, to assess its prediction validity. Thus, I will use a customized script, <code>make_features.py</code>, to transform and split the dataset into separate train and test datasets. I will fit the model and then use it to predict the risk of prostate cancer of the subjects included in the test dataset and then compare with actual status (control: prostate cancer in remission/cases: prostate cancer progressing) to see how well it&nbsp;predicted.</p>
<p>Check the <code>make_features.py</code>. Let&#8217;s examine it. First, I import the necessary&nbsp;modules:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">janitor</span> <span class="k">as</span> <span class="nn">jn</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span><span class="p">,</span> <span class="n">model_selection</span>
</code></pre></div>

<p><code>pathlib</code> is a module from the Python standard library. It helps file path management. <code>janitor</code> is a module for data clean-up and manipulation. <code>pandas</code> is also used for data manipulation and transformation, especially if it is contained on data frames. <code>sklearn</code> is an alias for <code>scikit-learn</code>. It is a powerhouse of several machine learning functions and utilities. Install all non-standard library modules using your Python package manager, usually <code>pip</code> or through anaconda, if you are using a conda environment with&nbsp;Python.</p>
<p>Next, I set up some constants that I will use&nbsp;later:</p>
<div class="highlight"><pre><span></span><code><span class="n">RANDOM_SEED</span><span class="o">=</span><span class="mi">42</span>
<span class="n">TEST_SIZE</span><span class="o">=</span><span class="mf">0.30</span>
<span class="n">INDEX</span><span class="o">=</span><span class="mi">676</span>
<span class="n">CORR_THRESHOLD</span><span class="o">=</span><span class="mf">0.80</span>
</code></pre></div>

<ul>
<li><code>RANDOM_SEED</code>: An integer used to initialize the pseudo-random number generator. It helps generate reproducible outputs in different&nbsp;sessions/computers;</li>
<li><code>TEST_SIZE</code>: A decimal (float) number indicating the size of the test dataset. Currently, it is 30% of the samples in the complete&nbsp;dataset;</li>
<li><code>INDEX</code>: An integer indicating a slicing index. I will explain it&nbsp;later.</li>
<li><code>CORR_THRESHOLD</code>: A float number indicating a threshold for eliminating correlated variables in the dataset; it helps overfitting by reducing the <a href="https://en.wikipedia.org/wiki/Multicollinearity">multicollinearity issue</a>.</li>
</ul>
<p>Next, I will indicate the path of the dataset, which i saved as a <span class="caps">CSV</span>&nbsp;file:</p>
<div class="highlight"><pre><span></span><code><span class="n">project_folder</span> <span class="o">=</span> <span class="n">Path</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">parent</span>
<span class="n">CSV_FILE</span> <span class="o">=</span> <span class="n">project_folder</span> <span class="o">/</span> <span class="s2">&quot;data&quot;</span> <span class="o">/</span> <span class="s2">&quot;interim&quot;</span> <span class="o">/</span> <span class="s2">&quot;prostate_cancer_dataset.csv&quot;</span>
</code></pre></div>

<p>See below the structure of the current working&nbsp;directory:</p>
<div class="highlight"><pre><span></span><code>.
├── data
│   ├── interim
│   │   └── prostate_cancer_dataset.csv
│   └── processed
├── models
└── src
    ├── features
    │   └── make_features.py
    └── models
        └── make_model.py
</code></pre></div>

<h2>Load data into&nbsp;Pandas</h2>
<p>Now, I create a <code>pandas.DataFrame</code> using the <code>read_csv</code> function, and assign it to <code>df</code> object:</p>
<div class="highlight"><pre><span></span><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">CSV_FILE</span><span class="p">)</span>
</code></pre></div>

<p>Check the column names with the <code>columns</code> method:</p>
<div class="highlight"><pre><span></span><code><span class="n">df</span><span class="o">.</span><span class="n">columms</span>
</code></pre></div>

<p>The <code>status</code> column contains the sample labels: <code>0</code> means &#8220;control&#8221; and <code>1</code> means &#8220;case&#8221;. The other columns are the variables (or features) of each&nbsp;sample.</p>
<h2>Dummy-encode categorical&nbsp;variables</h2>
<p>I can now transform the data, making it suitable for machine learning modeling. Luckily, the <span class="caps">TCGA</span> dataset has no missing values and no gross errors are present. Otherwise, I would have to impute missing values and correct the errors. Now I will recode the categorical variables in the dataset. To check which variables are categorical, use the <code>pandas</code> <code>dtypes</code> method. The variables labeled with <code>object</code> are usually categorical. If you see <code>object</code> beside the name of a variable you know it is not categorical, then it is possible that there are missing data or some other&nbsp;error.</p>
<div class="highlight"><pre><span></span><code><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h2>Split&nbsp;datasets</h2>
<p>With the transformed dataset, let&#8217;s go ahead and split the dataset into training and testing&nbsp;datasets.</p>
<div class="highlight"><pre><span></span><code><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">jn</span><span class="o">.</span><span class="n">get_features_targets</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target_columns</span><span class="o">=</span><span class="s2">&quot;status&quot;</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">TEST_SIZE</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_SEED</span>
<span class="p">)</span>
</code></pre></div>

<p>The <code>get_features_targets</code> from <code>janitor</code> module will get the <code>df</code> object and separate the sample labels from the variables (features). The features will then be assigned to object <code>X</code>, which will be instanced as a <code>pandas.DataFrame</code> and the <code>status</code> column (see the <code>target_columns</code> argument) will be put in the <code>y</code> object, which will be instanced as a <code>pandas.Series</code>.</p>
<p>The second function, <code>model_selection.train_test_split</code> from <code>sklearn</code> will split the <code>X</code> and <code>y</code> objects into its training and testing counterparts &#8212; therefore, four objects: <code>X_train</code>, <code>X_test</code>, <code>y_train</code> and <code>y_test</code>. Check the <code>TEST_SIZE</code> and <code>RANDOM_SEED</code> constants I set up in the beginning of the script being used here. They indicate that 30% of the dataset must be included as a test dataset (therefore 70% in the training dataset) and setting a integer into the <code>random_state</code> argument ensures that the splitting outputs can be&nbsp;reproduced.</p>
<p>Also note the <code>stratify</code> argument. It ensures that the same proportion of cases and controls are drawn for training and testing datasets. For this, I indicate the object containing the labels, which is <code>y</code>.</p>
<p>The commands below print the number of cases and controls for each&nbsp;dataset:</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Set has </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="si">}</span><span class="s2"> Positive Labels (cases) and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="si">}</span><span class="s2"> Negative Labels (controls)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Set has </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2"> Positive Labels (cases) and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2"> Negative Labels (controls)&quot;</span><span class="p">)</span>
</code></pre></div>

<p>The&nbsp;output:</p>
<div class="highlight"><pre><span></span><code>Training Set has 38 Positive Labels (cases) and 127 Negative Labels (controls)
Test Set has 16 Positive Labels (cases) and 55 Negative Labels (controls)
</code></pre></div>

<h2>Normalize&nbsp;data</h2>
<p>Now I will standardize (scale or <a href="https://en.wikipedia.org/wiki/Standard_score">Z-score normalize</a>) the numerical columns. For each numerical feature, I will calculate its mean and standard deviation. Then, for each observed value of the variable, I will subtract the mean and divide by the standard&nbsp;deviation.</p>
<p>After the dummy coding of the categorical variables, they were transposed to the end of the data frame. I manually checked the column names and identified the column index. I then sliced the list of column names and stored in the <code>num_cols</code> object:</p>
<div class="highlight"><pre><span></span><code><span class="n">num_cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)[:</span><span class="n">INDEX</span><span class="p">]</span>
</code></pre></div>

<p>That&#8217;s why I conveniently saved the index number into the <code>INDEX</code> variable at the beginning of the script. It helps code reusability with different data. It is one of the advantages of avoiding the so called <a href="https://www.pluralsight.com/tech-blog/avoiding-magic-numbers/">&#8220;magic numbers&#8221;</a>.</p>
<p>With the numeric columns identified, I then used the <code>StandardScaler()</code> function from <code>sklearn</code><span class="quo">&#8216;</span>s <code>preprocessing</code> module:</p>
<div class="highlight"><pre><span></span><code><span class="n">sca</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">[</span><span class="n">num_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">sca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">num_cols</span><span class="p">])</span>
<span class="n">X_test</span><span class="p">[</span><span class="n">num_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">sca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">num_cols</span><span class="p">])</span>
</code></pre></div>

<p>I used the function <code>fit_transform()</code> function in the <code>X_train</code> dataset, passing the <code>num_cols</code> list as the indication of which columns need to be normalized (using the brackets <code>[]</code> notation) and saving the resulting transformation with the same names into the <code>X_train</code> object. Thus, for all effects and purposes, I am replacing the old columns with the normalized&nbsp;columns.</p>
<p>Note that for <code>X_test</code> dataset I used a different formula, <code>transform()</code>. This is because I am using just the coefficients fitted by <code>fit_transform()</code> in the train dataset to generate the normalization in the test dataset. This way I am sure that the scaling is not &#8220;contaminated&#8221; by the test data, that is supposed to not seem before the classification model&nbsp;fitting.</p>
<h2>Remove correlated&nbsp;features</h2>
<p>Now I will filter out correlated features. Please note that I would not normally do this with genomic data, but since here is just an exercise, I will show how to do it so you can apply to your projects when necessary. Check below the code (hat tip to <a href="https://towardsdatascience.com/feature-selection-in-python-recursive-feature-elimination-19f1c39b8d15">Dario Radečić</a> for the&nbsp;snippet):</p>
<div class="highlight"><pre><span></span><code><span class="n">correlated_features</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">CORR_THRESHOLD</span><span class="p">:</span>
            <span class="n">colname</span> <span class="o">=</span> <span class="n">correlation_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">correlated_features</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
</code></pre></div>

<p>The commands above will calculate the pairwise correlation between all features in the dataset, creating a <code>correlation_matrix</code>. If the correlation between two features is above <code>CORR_THRESHOLD</code> (currently 0.80), the loop will store the name of one of them into the <code>correlated_features</code> set, ensuring that no names are repeated. If you want to know how may pairs of correlated features were present in the dataset, run the command below to print to the&nbsp;console:</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of correlated feature pairs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">correlated_features</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Then I can convert the set as list and pass it to <code>pandas</code><span class="quo">&#8216;</span> <code>drop()</code> method:</p>
<div class="highlight"><pre><span></span><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">correlated_features</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">correlated_features</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>

<p>I dropped the columns and saved the data frames with the same name for convenience. Note the <code>axis=1</code> argument, it tells <code>drop()</code> to look the <em>columns</em> for the list elements and then remove&nbsp;them.</p>
<h2>Serializing datasets for future&nbsp;use</h2>
<p>Finally, the train and test datasets are ready for use! To save them into disk for later use, I will use <code>pandas</code><span class="quo">&#8216;</span> <code>to_pickle</code> method. A &#8220;pickled&#8221; Python object is <em>serialized</em>: it was converted into a series of bytes (a byte stream). This byte stream therefore can be &#8220;unpickled&#8221; to restore the object exactly as it was when was &#8220;pickled&#8221;. This is useful to backup data, share with others, and so on. Using <code>pathlib.Path</code> notation, I saved the objects into the &#8220;data/processed/&#8221;&nbsp;folder:</p>
<div class="highlight"><pre><span></span><code><span class="n">X_train</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">project_folder</span><span class="o">/</span><span class="s2">&quot;data&quot;</span><span class="o">/</span><span class="s2">&quot;processed&quot;</span><span class="o">/</span><span class="s2">&quot;X_train&quot;</span><span class="p">)</span>
<span class="n">X_test</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">project_folder</span><span class="o">/</span><span class="s2">&quot;data&quot;</span><span class="o">/</span><span class="s2">&quot;processed&quot;</span><span class="o">/</span><span class="s2">&quot;X_test&quot;</span><span class="p">)</span>
<span class="n">y_train</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">project_folder</span><span class="o">/</span><span class="s2">&quot;data&quot;</span><span class="o">/</span><span class="s2">&quot;processed&quot;</span><span class="o">/</span><span class="s2">&quot;y_train&quot;</span><span class="p">)</span>
<span class="n">y_test</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">project_folder</span><span class="o">/</span><span class="s2">&quot;data&quot;</span><span class="o">/</span><span class="s2">&quot;processed&quot;</span><span class="o">/</span><span class="s2">&quot;y_test&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Note: pickled objects are Python-specific only &#8212; non-Python programs may not be able to reconstruct pickled Python objects. <span class="caps">WARNING</span>: never, <span class="caps">NEVER</span>, unpickle data you do not trust. As it says in the Python documentation: <a href="https://docs.python.org/3/library/pickle.html">&#8220;It is possible to construct malicious pickle data which will execute arbitrary code during unpickling&#8221;</a>.</strong></p>
<p>Now, my folders are like&nbsp;this:</p>
<div class="highlight"><pre><span></span><code>.
├── data
│   ├── interim
│   │   └── prostate_cancer_dataset.csv
│   └── processed
│       ├── X_train
│       ├── X_test
│       ├── y_train
│       └── y_test
├── models
└── src
    ├── features
    │   └── make_features.py
    └── models
        └── make_model.py
</code></pre></div>

<h2>Conclusion</h2>
<p>In this post, I showed how&nbsp;to:</p>
<ul>
<li>Import a <span class="caps">CSV</span> dataset into <code>pandas</code>;</li>
<li>Dummy-encode categorical&nbsp;data;</li>
<li>Split the dataset into train/test&nbsp;datasets;</li>
<li>Normalize data&nbsp;(Z-scores);</li>
<li>Serialize (pickle) the datasets for future&nbsp;use.</li>
</ul>
<p>Go to the <a href="https://antoniocampos13.github.io/machine-learning-with-python-supervised-classification-of-tcga-prostate-cancer-data-part-2-making-a-model.html">Part 2</a>, where I show how to use the datasets to generate a classification model for predicting risk of prostate cancer disease progression with the <code>make_model.py</code> script.</p>
<p><em>Subscribe to my <a href="https://antoniocampos13.github.io/feeds/all.rss.xml"><span class="caps">RSS</span> feed</a>, <a href="https://antoniocampos13.github.io/feeds/all.atom.xml">Atom feed</a> or <a href="https://t.me/joinchat/AAAAAEYrNCLK80Fh1w8nAg">Telegram channel</a> to keep you updated whenever I post new&nbsp;content.</em></p>
<h2>References</h2>
<p><a href="https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga">The Cancer Genome Atlas&nbsp;Program</a></p>
<p><a href="http://www.cancergenomicscloud.org/">Cancer Genomics&nbsp;Cloud</a></p>
<p><a href="https://scikit-learn.org/stable/">scikit-learn: machine learning in Python - scikit-learn 0.23.2&nbsp;documentation</a></p>
<p><a href="https://en.wikipedia.org/wiki/Multicollinearity">Multicollinearity -&nbsp;Wikipedia</a></p>
<p><a href="https://en.wikipedia.org/wiki/Standard_score">Standard score -&nbsp;Wikipedia</a></p>
<p><a href="https://www.pluralsight.com/tech-blog/avoiding-magic-numbers/">Avoiding Magic&nbsp;Numbers</a></p>
<p><a href="https://towardsdatascience.com/feature-selection-in-python-recursive-feature-elimination-19f1c39b8d15">Feature Selection in Python — Recursive Feature&nbsp;Elimination</a></p>
<p><a href="https://docs.python.org/3/library/pickle.html">pickle — Python object serialization | Python 3.9.0&nbsp;documentation</a></p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://antoniocampos13.github.io/tag/bioinformatics.html">Bioinformatics</a>
      <a href="https://antoniocampos13.github.io/tag/gene-expression.html">gene expression</a>
      <a href="https://antoniocampos13.github.io/tag/machine-learning.html">machine learning</a>
      <a href="https://antoniocampos13.github.io/tag/supervised-classification.html">supervised classification</a>
    </p>
  </div>





</article>

    <footer>
<p>
  &copy; 2020 Antonio Victor Campos Coelho - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
           src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Antonio's Portfolio ",
  "url" : "https://antoniocampos13.github.io",
  "image": "https://avatars.githubusercontent.com/antoniocampos13",
  "description": "Data Science Portfolio by Antonio Victor Campos Coelho"
}
</script>


</body>
</html>